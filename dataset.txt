A blue-skinned man is smiling with his hands together in front of his chest. He is wearing a brown shirt and a white patterned shawl. A brick wall and green foliage are in the background.


Three copper pheasant birds are standing on a ledge. The birds have long green tails and orange heads. A building and some greenery are in the background.


A phone screen displays a Domino's ad for a blue pizza. The pizza has a cheese sauce center and is topped with blue cheese cubes and green peppers. The ad text reads "CHEESY FIXATION SORTED".


A flag with green white and blue stripes is flying on a tall gray pole. The pole is next to a blue building with a dark roof. The sky is light brown.


 Welcome back Aliens my name is Avindredi and in this video we'll talk about AI engineering or we have this new role called AI engineer. So let's talk about it. See we talk about AI and it's not something new it's there from a long time from 1950s. We got certain things from 1970s. We got some improvements and then every year we saw something coming. But then it was all for the enterprises how they can build certain things with the help of AI and we are hearing about Google AI Watson from IBM and from different company. But in 2022 this is a time when open AI made Jagipiti. Now this was the first time I think where AI was accessible for normal users and things started changing very fast after that point. And now we are bit scared if AI going to take over all the jobs not just for developers, for writers, for trainers because of the videos. I don't think you need to watch my video in future. There will be a AI bot teaching you. Okay, that's a different thing. Okay, so let's see that in the future. I'm bit scared, but that's fine. The point here is as a software developer like you and me. What is our role? Now, yeah, they are talking about AI is going to replace software developer. They can build applications, but this also gives you a power to use AI in building softwares. It's not about building software the way you are doing. We have to add something extra and that something extra is the AI capabilities in your existing application or the new application. The way you build software is changing. So AI is not just for PSDs or data scientist. It is for software developers as well. And we have to understand how do we do it? And if you can integrate AI into your application as a software developer, you can call yourself now as a AI engineer. So your role switches from a software engineer to AI engineer. So what is changing? See when you build application, of course, your idea is to solve a problem. So there's a problem in the world, which you're trying to solve by building application. Or maybe you're creating a new problem and solving it. That's a different point. But the idea is to solve a problem with the help of software. And the way your software works is how you define it to work. Basically, when you build a software, we go it in certain steps. We have something called S DLC, which is software development lifecycle. We go with different phases. If there's a problem, you will understand the requirement. Then you will design it, then you will code it, then you will test it, and then you will deploy it and maintain. That's the normal process. Of course, you can add certain things here. You can remove some stages like if you are building a college project or dummy project, who is doing testing, right? But yes, if you want to do that in the enterprise level, testing is very important. Now what happens in all the phases here? In the requirement phase, you get the requirement in the analysis phase, you understand what is requirement is, and then you start designing the model. Okay, not AI model, basically how the software will work. And you define everything what should happen when what kind of input you're going to get from the user, what actions you are going to perform on that. So, let's say if you want to achieve certain things, you will say, click this button, then this will happen. Now based on certain conditions, you want to execute certain things. Now you have to define everything. You have to also make sure that by just by clicking that button, you're not launching a rocket or shutting down the system. Basically you check everything in that design phase, and then you will start implementing it in the coding phase. Now this is what we want to change. Why as a software developer, you have to define what should be the logic, what should happen when what if AI can generate logic based on what it has learned. So you are not defining the logic, it is AI, you just say what you want to achieve based on the user interactions. Now how you are going to do this? See there are a lot of models available in the market, right? If you heard about GPT or Gemini or Anthropic Cloud, basically all these are models which you can use. They are not just a fun tool to have some fun now. They are production ready APIs which you can use and implement in your application. Now question is how will you do it? Now this companies or this models, they also give you APIs, not for free. Yeah, you can use open source models if you want it for free or they might also provide you some free APIs to use. But if you want to use them full flesh, of course, you will pay for it or you will get the access anyhow. But they will give you APIs. Now you have to integrate those APIs in your application. So it is your job as an AI engineer in between to help to connect this application with the AI models. And the good thing is you are 80% there is because you know how everything works. You know how to build a software. In fact, not just into the coding phase, you understand all the steps. You know what are requirements are, you know what is possible, what is not possible. I don't think in the AI world anything is impossible now, but you know the limits, right? And then you know how a software should work, how user will interact. You also know how to code it. You know one of the programming language, then you know what is testing concept all together is what is new for you is integrating those AI tools or AI models in your application. So you can think about this as AI is not replacing you is more about enhancing your existing capability. And with that, you're not just building an application, you're building a smart or intelligent applications. So now let's go back to that S DLC, what are the things which are going to change? Of course, the normal S DLC will remain same, but you have to inject certain more steps in between example, how will you interact with the AI? And thanks to chat, GPT and all this models or the applications, you know how to talk to AI. There is something called prompt engineering. There are good ways of doing it, there are bad ways of doing it, and we have to learn the good ways to make your application much better. Second is it's not just about working with one database now. So of course to store your data, you're going to use some database. But if you want to use AI, we have to add some extra concepts like embedding and vector databases and also drag why you will need that. So let's say you have an application which you are building for a client who is into ticket booking. So maybe fly tickets or bus tickets or train tickets. So they are into that. And now when a new user comes in, now of course, if I don't use or they have to create an account, now how they will create an account. Yeah, I know it is straightforward. You can basically open the page and there should be an option of creating an account. But let's say if they get stuck somewhere because it's asked you for extra information and now they don't know how to proceed. So of course you will provide a chatbot, right? And that's the default behavior nowadays. You've got a chatbot there and you will say, okay, I don't know how to create an account in this application. Now if you think about this chatbot, it might be using some models behind the scene like open AI or cloud or whatever model you have. Now this model, when you ask, they will know how to create an account in general. Okay. Now when you say in general, maybe they know how to get account on Google or Facebook or maybe Amazon. And they will give you steps how to get account on those applications. And that's where it is hallucinating. Right. We are asking for our application. It is giving the data about those websites. Now this is where you have to inject certain documents in your board by saying. See, it's not just about interacting with the open AI. This is our company policies. This is how you create account for this particular application. So you will inject those documents in the AI or in your prompt. And that's what you can do with the help of rag. So those documents goes into the database, not the normal database. If you're thinking it is a vector database. Now to convert that from text to two numbers which vector data was support, you need to have embeddings. Now if you're not understanding all those things, don't worry. We'll go to them in detail later. But I just wanted to give you an idea. It's not just about using models. And you will call your efforts as AI engineer. You have to do all those steps as well. Prompt engineering, embedding vectors, rag. And also how do you deploy the application now? Because it's not just a normal application. You are interacting with the models. You are storing that data in the vector database as well. So it changes the way you do DevOps now. So we should call it as LLM ops now. That sounds much better. Right. So things are changing. Apart from it, you have to also fine tune your AI model. You can't simply use OpenAI by saying it should behave the way I want. Example, let's say if I'm building my own AI tutor. And if you say, hey, I want to learn Java or maybe I want to learn blockchain and AI tutor with the help of OpenAI it will give you the entire document. Hey, now read this. But then I want the AI tutor or the model which you are using should behave like the way I teach it should teach the way I teach. How will I do that? And that's where I have to fine tune my AI specifically for education, specifically for the way we work. Okay. So those things also included in AI engineering. Now the question is, do we have to also build models not necessarily because all these companies are already doing it. You don't have to build your own models. You can do that. Okay. Nobody stopping you to build your own models. But the question is should we. And yes, if you are a company who want to build their own models, please, you know, we need good models in the market, competing with existing models. But let's say if your idea is just to build your application smart, it's good to use the existing models. If you don't want to use the proprietary models, you can also use open source models. You can run it on your local hardware and you can make it work. You can you can do the configuration for that. You can change the way it works and the data will belong to you. Okay. If you want to achieve that. But do you need to know the basics of AI a bit? Yes, you should. You know, should you understand how AI works, how this model works, what is neural networks, basic software will be needed. And that should be enough. You don't have to go in depth because when I started AI, I started with that. I started with mathematics, statistics, then understanding what is machine learning, understanding different algorithms there. But now when I when I'm trying to be an engineer now, I'm not using them. But yes, it helps me to understand how they are doing it when the new models comes into picture. I know what is changing and that should be enough for you. And before we end this, remember one thing. It's not AI is going to replace the developers. It's the developers who are using AI are going to replace developers who are not using AI. And I want to add one more point. Now you might be thinking when you add all those data, but you know, there are a lot of steps in between when you use the models, it is will it will cost. And yes, it will cost, but to whom if you are going to sell the products to your customer, they will be happy right because the businesses looks for values. And if you can provide values, they are going to pay for it. And if you have a client who got competition in the market and if they have AI, of course, they are ready to pay for it. And ultimately, they can keep their customers happy by customizing it as per their needs. So yeah, that's all about AI engineering and the plan is to create the series on it. Let me know your thoughts in the comments. And if you're excited, let me know so that I will get motivated and I will start the series soon. Thank you so much for watching. See you in the next part. Bye.


 Remember how back in the day people would Google themselves, you type your name into a search engine and you see what it knows about you. Well, the modern equivalent of that is to do the same thing with a chatbot. So when I ask a large language model, who is Martin Keene? Well, the response varies greatly depending upon which model I'm asking because different models, they have different training data sets, they have different knowledge cut off dates. So what a given model knows about me, well, it differs greatly, but how could we improve the models answer? Well, there's three ways. So let's start with a model here. And we're going to see how we can improve its responses. Well, the first thing it could do is it could go out and it could perform a search, a search for new data that either wasn't in its training data set or it was just data that became available. After the model finished training and then it could incorporate those results from the search back into its answer. That is called rag or retrieval augmented generation. That's one method or we could pick a specialized model, a model that's been trained on, let's say transcripts of these videos. That would be an example of something called fine tuning or we could ask the model a query that better specifies what we're looking for. So maybe the LLM already knows plenty about the Martin Keene's of the world, but let's tell the model that we're referring to the Martin Keene who works at IBM rather than the Martin Keene that founded Keene shoes. That is an example of prompt engineering three ways to get better outputs out of large language models, each with their pluses and minuses. So let's start with rag. So let's break it down. First there's retrieval. So retrieval of external up to date information. Then there's augmentation. That's augmentation of the original prompt with the retrieved information added in and then finally there's generation. That's generation of a response based on all of this enriched context. So we can think of it like this. So we start with a query and the query comes in to a large language model. Now what rag is going to do is it's first going to go searching through a corpus of information. Do we have this corpus here? Full of some sort of data. Now perhaps that's your organization's documents. There might be spreadsheets PDFs internal wikis, you know stuff like that. But unlike a typical search engine that just matches keywords, rag converts both your question, the query and all of the documents into something called vector embeddings. So these are all converted into vectors essentially turning words and phrases into long lists of numbers that capture their meaning. So when you ask a query like what was our company's revenue growth last quarter? Well rag will find documents that are mathematically similar in meaning to your question, even if they don't use the exact same words. So it might find documents mentioning fourth quarter performance or quarterly sales. Those don't contain the keyword revenue growth, but they are semantically similar. Now once rag finds the relevant information, it adds this information back into your original query before passing it to the language model. So instead of the model just kind of guessing based on its training data, it can now generate a response that incorporates your actual facts and figures. So this makes rag particularly valuable when you are looking for information that is up to date. And it's also very valuable when you need in to add in information that is domain specific as well. But there are some costs to this that get with the red pen. So one cost that would be the cost of performance for performing all of this because you have this retrieval step here and that adds latency to each query compared to a simple prompt to a model. There are also costs related to just kind of the processing of this as well. So if we think about what we're having to do here, we've got documents that need to be vector embeddings. And we need to store these vector embeddings in a database. All of this adds to processing costs, adds to infrastructure costs to make this solution work. Alright next up, fine tuning. So remember how we discuss getting better answers about me by training a model specifically on let's say my video transcripts. Well that is fine tuning in action. So what we do with fine tuning is we take a model but specifically an existing model. And that existing model has broad knowledge and then we're going to give it additional specialized training on a focused data set. So this is now specialized to what we want to develop particular expertise on. Now during fine tuning we're updating the model's internal parameters through additional training. So the model starts out with some weights here like this. And those weights were optimized during its initial pre-training. And as we fine tune, we're making small adjustments here to the model's weights using this specialized data set. So this is being incorporated. Now this process typically uses supervised learning where we provide input output pairs that demonstrate the kind of responses we want. So for example if we're fine tuning for technical support we might provide thousands of examples of customer queries. And those would be paired with correct technical responses. The model adjusts its weights through back propagation to minimize the difference between its predicted outputs and the targeted responses. So we're not just teaching the model new facts here. We're actually modifying how it processes information. The model is learning to recognize domain specific patterns. So fine tuning shows its strength when you particularly need a model that has very deep domain expertise. That's what we can really add in with fine tuning. And also it's much faster specifically at inference time. So when we are putting the queries in, it's faster than rag because it doesn't need to search through external data. And because the knowledge is kind of baked into the model's weights, you don't need to maintain a separate vector database. But there's some downsides as well. Well there's certainly issues here with the training complexity of all of this. You're going to need thousands of high quality training examples. There are also issues with computational cost. The computational cost for training this model can be substantial and is going to require a whole bunch of GPUs. And there's also challenges related to maintenance as well. Because unlike rag where you can easily add new documents to your knowledge base at any point, updating a fine tune model requires another round of training. And then perhaps most importantly of all, there is a risk of something called catastrophic forgetting. Now that's where the model loses some of its general capabilities while it's busy learning these specialized ones. So finally let's explore prompt engineering. Now specifying Martin Keanu works at IBM versus Martin Keanu founded Keanu's shoes. That's prompt engineering but it's most basic. Prompt engineering goes far beyond simple clarification. So let's think about when we input a prompt, the model receives this prompt and it processes it through a series of data. And these layers are essentially attention mechanisms and each one focuses on different aspects of your prompt text that came in. And by including specific elements in your prompt, so examples or context or how you want the format to look, you're directing the model's attention to relevant patterns it learned during training. So for example, telling a model to think about this step by step that activates patterns it learned from training data where methodical reasoning led to accurate results. So a well engineered prompt can transform a model's output without any additional training or without data retrieval. So take an example of a prompt. Let's say we say is this code secure not a very good prompt and engineered prompt it might read a bit more like this. It's much more detailed now we haven't changed the model. We haven't added new data. We've just better activated is existing capabilities. Now I think the benefits to this pretty obvious one is that we don't need to change any of our back end infrastructure here because there are no infrastructure changes at all in order to prompt better. It's all on the user. There's also the benefit that by doing this you get to see immediate responses and immediate results to what you do. We don't have to add in new training data or any kind of data processing, but of course there are some limitations to this as well. Prompt engineering is as much an art as it is a science. So there is certainly a good amount of trial and error in this sort of process to find effective problems. And you're also limited in what you can do here. You're limited to existing knowledge because you're not able to actually add anything else in here. No additional amount of prompt engineering is going to teach it truly new information. You're not going to teach the model anything that's outdated in the model. So we've talked about now rag as being one option and we talked about fine tuning as being another one. And now just now we've talked about prompt engineering as well. And I've really talked about those as three different distinct things here. They're commonly used actually in combination. We might use all three together. So consider a legal AI system. Rag that could retrieve specific cases and recent court decisions. The prompt engineering part that could make sure that we follow proper legal document formats by asking for it. And then fine tuning that could help the model master firm specific policies. I mean, basically we can think of it like this. We can think that prompt engineering offers flexibility and immediate results, but it can't extend knowledge. Rag that can extend knowledge. It provides up to date information, but with computational overhead and then fine tuning that enables deep domain expertise, but it requires significant resources and maintenance. Basically it comes down to picking the methods that work for you. You know, we've we've shook them a long way from vanity searching on Google.


